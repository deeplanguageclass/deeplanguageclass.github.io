# Machine Learning for Natural Language Processing

Recent progress in machine learning for natural language is significant, however language poses some unique challenges.

In this class we will start with natural language processing fundamentals and the current results of state-of-the-art approaches across tasks.  We will focus on deep learning – the motivations behind word vectors and sequence output, and how to apply effective approaches to real tasks with industrial-strength libraries and datasets.
We will also keep in view how natural language tasks relate to tasks in other areas of machine learning. 

Instructors: Erik Arakelyan + Adam Bittlingmayer

Prerequisites: solid coding skills, strong analytical ability, fluency in multiple human languages, a Unix system

*This class is part of the [2018 YSU – ISTC Join Summer School on Machine Learning](http://mathschool.ysu.am/mss2018/).*

## [I - Fundamentals](fundamentals)

## [II - Deep Learning](deeplearning)

## [III - Project](project)

## Resources

See [NLP Guide](https://nlpguide.github.io/)
